{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "from IPython.display import display \n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trait_groups</th>\n",
       "      <th>trait_variations</th>\n",
       "      <th>file_name</th>\n",
       "      <th>quant</th>\n",
       "      <th>weights</th>\n",
       "      <th>old_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Background</td>\n",
       "      <td>Lines</td>\n",
       "      <td>Lines Bg</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>Lines Bg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Background</td>\n",
       "      <td>Green</td>\n",
       "      <td>Bg1</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>Bg1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Background</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Bg2</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>Bg2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Background</td>\n",
       "      <td>Light Pink</td>\n",
       "      <td>Bg3</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>Bg3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black Bg</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>Black Bg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>Royal Coat</td>\n",
       "      <td>19 Cloth</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>19 Cloth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Clothing2</td>\n",
       "      <td>Royal Coat</td>\n",
       "      <td>19 Cloth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19 Cloth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Ancestry</td>\n",
       "      <td>Demigod</td>\n",
       "      <td>demi</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>demi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Ancestry</td>\n",
       "      <td>Royal</td>\n",
       "      <td>king</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>king</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trait_groups trait_variations file_name   quant  weights  old_name  \\\n",
       "0     Background            Lines  Lines Bg   588.0   0.0588  Lines Bg   \n",
       "1     Background            Green       Bg1   588.0   0.0588       Bg1   \n",
       "2     Background             Pink       Bg2   588.0   0.0588       Bg2   \n",
       "3     Background       Light Pink       Bg3   588.0   0.0588       Bg3   \n",
       "4     Background            Black  Black Bg   588.0   0.0588  Black Bg   \n",
       "..           ...              ...       ...     ...      ...       ...   \n",
       "224     Clothing       Royal Coat  19 Cloth   100.0   0.0100  19 Cloth   \n",
       "225     Clothing             None      None   400.0   0.0400      None   \n",
       "226    Clothing2       Royal Coat  19 Cloth     NaN   0.0000  19 Cloth   \n",
       "227     Ancestry          Demigod      demi  2000.0   0.2000      demi   \n",
       "228     Ancestry            Royal      king  8000.0   0.8000      king   \n",
       "\n",
       "     new_name  Unnamed: 7  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "..        ...         ...  \n",
       "224       NaN         NaN  \n",
       "225       NaN         NaN  \n",
       "226       NaN         NaN  \n",
       "227       NaN         NaN  \n",
       "228       NaN         NaN  \n",
       "\n",
       "[229 rows x 8 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import trait files\n",
    "\n",
    "traits_file = pd.read_csv(\"Traits-Table.csv\", header=0)\n",
    "exception_file = pd.read_csv(\"Exceptions-Table.csv\", header=0)\n",
    "traits_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of trait variations for each group\n",
    "\n",
    "background = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Background\"].values.tolist()\n",
    "skin = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Skin\"].values.tolist()\n",
    "clothing = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Clothing\"].values.tolist()\n",
    "glasses = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Glasses\"].values.tolist()\n",
    "hand = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hands\"].values.tolist()\n",
    "hat = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hat\"].values.tolist()\n",
    "mask = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Mask\"].values.tolist()\n",
    "several = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Several\"].values.tolist()\n",
    "ancestry = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Ancestry\"].values.tolist()\n",
    "\n",
    "\n",
    "# List to be used in layer sequences only\n",
    "\n",
    "glasses2 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Glasses2\"].values.tolist()\n",
    "glasses3 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Glasses3\"].values.tolist()\n",
    "glasses4 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Glasses4\"].values.tolist()\n",
    "several2 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Several2\"].values.tolist()\n",
    "several1 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Several1\"].values.tolist()\n",
    "several3 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Several3\"].values.tolist()\n",
    "hat2 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hat2\"].values.tolist()\n",
    "hat3 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hat3\"].values.tolist()\n",
    "hat4 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hat4\"].values.tolist()\n",
    "hat5 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Hat5\"].values.tolist()\n",
    "beard1 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Beard1\"].values.tolist()\n",
    "beard2 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Beard2\"].values.tolist()\n",
    "clothing2 = traits_file[\"trait_variations\"][traits_file[\"trait_groups\"] == \"Clothing2\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weights for each trait variation\n",
    "\n",
    "background_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Background\"].values.tolist()\n",
    "skin_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Skin\"].values.tolist()\n",
    "clothing_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Clothing\"].values.tolist()\n",
    "glasses_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Glasses\"].values.tolist()\n",
    "hand_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Hands\"].values.tolist()\n",
    "hat_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Hat\"].values.tolist()\n",
    "mask_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Mask\"].values.tolist()\n",
    "several_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Several\"].values.tolist()\n",
    "ancestry_weights = traits_file[\"weights\"][traits_file[\"trait_groups\"] == \"Ancestry\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.065, 0.01, 0.045, 0.055, 0.045, 0.08, 0.03, 0.04, 0.05, 0.58]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glasses_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file names (if there is more than on trait with the same name, this has to be adjusted)\n",
    "\n",
    "file_names = traits_file[[\"trait_variations\", \"file_name\"]]\n",
    "file_names_list = file_names.to_dict('split')[\"data\"]\n",
    "file_names_dict = {k[0]: k[1:][0] for k in file_names_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Traits\n",
    "\n",
    "TOTAL_IMAGES = 7500  # Number of random unique images we want to generate\n",
    "\n",
    "all_images = [] \n",
    "all_images_no_bg = []\n",
    "\n",
    "# A recursive function to generate unique image combinations\n",
    "def create_new_image():\n",
    "    \n",
    "    new_image = {} \n",
    "    new_image_no_bg = {} #\n",
    "\n",
    "    # For each trait category, select a random trait based on the weightings \n",
    "    new_image [\"background\"] = random.choices(background, background_weights)[0]\n",
    "    new_image [\"skin\"] = random.choices(skin, skin_weights)[0]\n",
    "    new_image [\"clothing\"] = random.choices(clothing, clothing_weights)[0]\n",
    "    new_image [\"glasses\"] = random.choices(glasses, glasses_weights)[0]\n",
    "    new_image [\"hand\"] = random.choices(hand, hand_weights)[0]\n",
    "    new_image [\"hat\"] = random.choices(hat, hat_weights)[0]\n",
    "    new_image [\"mask\"] = random.choices(mask, mask_weights)[0]\n",
    "    new_image [\"several\"] = random.choices(several, several_weights)[0]\n",
    "    \n",
    "  \n",
    "    # Treat exceptions\n",
    "    \n",
    "    new_image_list = list(new_image.values())\n",
    "    for i in new_image_list:\n",
    "        exception_list = list(exception_file[exception_file[\"key_trait\"] == i][\"Exception\"])\n",
    "        if len((set(new_image_list) & set(exception_list))) != 0:\n",
    "            return create_new_image()\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    # Removing background, eyes, mouth from uniqueness comparison\n",
    "    new_image_no_bg[\"skin\"] = new_image [\"skin\"]\n",
    "    new_image_no_bg[\"clothing\"] = new_image [\"clothing\"]\n",
    "    new_image_no_bg[\"glasses\"] = new_image [\"glasses\"]\n",
    "    new_image_no_bg[\"hat\"] = new_image [\"hat\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if new_image_no_bg in all_images_no_bg:\n",
    "        return create_new_image()\n",
    "    else:\n",
    "        return new_image, new_image_no_bg\n",
    "    \n",
    "    \n",
    "    #if new_image in all_images:\n",
    "    #    return create_new_image()\n",
    "    #else:\n",
    "    #    return new_image\n",
    "                                              \n",
    "   \n",
    "    \n",
    "# Generate the unique combinations based on trait weightings\n",
    "for i in range(TOTAL_IMAGES): \n",
    "    \n",
    "    new_trait_image = create_new_image()\n",
    "    \n",
    "    all_images.append(new_trait_image[0])\n",
    "    all_images_no_bg.append(new_trait_image[1])\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all images unique? True\n"
     ]
    }
   ],
   "source": [
    "# Returns true if all images are unique\n",
    "def all_images_unique(all_images):\n",
    "    seen = list()\n",
    "    return not any(i in seen or seen.append(i) for i in all_images)\n",
    "\n",
    "print(\"Are all images unique?\", all_images_unique(all_images))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all images unique regardless? True\n"
     ]
    }
   ],
   "source": [
    "# Returns true if all images excluding background and other qualitative traits are unique\n",
    "def all_images_unique(all_images_no_bg):\n",
    "    seen = list()\n",
    "    return not any(i in seen or seen.append(i) for i in all_images_no_bg)\n",
    "#\n",
    "print(\"Are all images unique regardless?\", all_images_unique(all_images_no_bg))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file for review\n",
    "\n",
    "# Add temporary token id:\n",
    "\n",
    "i = 0\n",
    "for item in all_images:\n",
    "    item[\"tokenId\"] = i\n",
    "    i = i + 1\n",
    "\n",
    "# Create pandas\n",
    "\n",
    "\n",
    "\n",
    "df_tb_reviewed = pd.DataFrame.from_dict(all_images)\n",
    "df_tb_reviewed = df_tb_reviewed.set_index('tokenId')\n",
    "\n",
    "df_tb_reviewed.to_csv(\"file_tb_reviewed.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import reviewed file\n",
    "\n",
    "#df_reviewed = pd.read_csv(\"file_reviewed.csv\", header=0)\n",
    "#all_images_rev = df_reviewed.to_dict(orient='records')\n",
    "#len(all_images_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# ONLY RUN THIS IF SKIPPING FILE REVIEW\n",
    "\n",
    "all_images_rev = copy.deepcopy(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add token Id to each image\n",
    "i = 0\n",
    "for item in all_images_rev:\n",
    "    item[\"tokenId\"] = i\n",
    "    i = i + 1\n",
    "#    if i<=650: \n",
    "#        item[\"ancestry\"] = \"god\"\n",
    "#    elif 1500>=i>650:\n",
    "#        item[\"ancestry\"] = \"demi\"\n",
    "#    elif 3000>=i>1500:\n",
    "#        item[\"ancestry\"] = \"king\"\n",
    "#    elif 5000>=i>3000:\n",
    "#        item[\"ancestry\"] = \"prince\"\n",
    "#    elif 10000>=i>5000:\n",
    "#        item[\"ancestry\"] = \"duke\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Trait Counts\n",
    "\n",
    "background_count = {}\n",
    "for item in background:\n",
    "    background_count[item] = 0\n",
    "    \n",
    "skin_count = {}\n",
    "for item in skin:\n",
    "    skin_count[item] = 0\n",
    "    \n",
    "    \n",
    "clothing_count = {}\n",
    "for item in clothing:\n",
    "    clothing_count[item] = 0\n",
    "\n",
    "glasses_count = {}\n",
    "for item in glasses:\n",
    "    glasses_count[item] = 0\n",
    "    \n",
    "    \n",
    "hand_count = {}\n",
    "for item in hand:\n",
    "    hand_count[item] = 0\n",
    "    \n",
    "    \n",
    "hat_count = {}\n",
    "for item in hat:\n",
    "    hat_count[item] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "mask_count = {}\n",
    "for item in mask:\n",
    "    mask_count[item] = 0\n",
    "    \n",
    "several_count = {}\n",
    "for item in several:\n",
    "    several_count[item] = 0\n",
    "    \n",
    "ancestry_count = {}\n",
    "for item in ancestry:\n",
    "    ancestry_count[item] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "for image in all_images_rev:\n",
    "    background_count[image[\"background\"]] += 1\n",
    "    skin_count[image[\"skin\"]] += 1\n",
    "    clothing_count[image[\"clothing\"]] += 1\n",
    "    glasses_count[image[\"glasses\"]] += 1\n",
    "    hand_count[image[\"hand\"]] += 1\n",
    "    hat_count[image[\"hat\"]] += 1\n",
    "    mask_count[image[\"mask\"]] += 1\n",
    "    several_count[image[\"several\"]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas df for images\n",
    "df_tokens = pd.DataFrame.from_dict(all_images_rev)\n",
    "df_tokens = df_tokens.set_index('tokenId')\n",
    "\n",
    "df_tokens.to_csv(\"file_tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas df for rarity\n",
    "\n",
    "df_rarity_1 = pd.DataFrame.from_dict(OrderedDict(sorted(background_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_1['trait_group']=\"background\"\n",
    "\n",
    "df_rarity_2 = pd.DataFrame.from_dict(OrderedDict(sorted(skin_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_2['trait_group']=\"skin\"\n",
    "\n",
    "df_rarity_3 = pd.DataFrame.from_dict(OrderedDict(sorted(clothing_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_3['trait_group']=\"clothing\"\n",
    "\n",
    "df_rarity_4 = pd.DataFrame.from_dict(OrderedDict(sorted(glasses_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_4['trait_group']=\"glasses\"\n",
    "\n",
    "df_rarity_6 = pd.DataFrame.from_dict(OrderedDict(sorted(hand_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_6['trait_group']=\"hand\"\n",
    "\n",
    "df_rarity_7 = pd.DataFrame.from_dict(OrderedDict(sorted(hat_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_7['trait_group']=\"hat\"\n",
    "\n",
    "\n",
    "df_rarity_8 = pd.DataFrame.from_dict(OrderedDict(sorted(mask_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_8['trait_group']=\"mask\"\n",
    "\n",
    "df_rarity_9 = pd.DataFrame.from_dict(OrderedDict(sorted(several_count.items(), key=lambda t: t[1])), orient='index', columns=[\"count\"])\n",
    "df_rarity_9['trait_group']=\"several\"\n",
    "\n",
    "\n",
    "df_rarity = pd.concat([df_rarity_1, df_rarity_2, df_rarity_3, df_rarity_4, df_rarity_6, df_rarity_7, df_rarity_8, df_rarity_9])\n",
    "\n",
    "df_rarity.to_csv(\"file_rarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_rev_temp = copy.deepcopy(all_images_rev)\n",
    "\n",
    "#### Generate Images    \n",
    "for item in all_images_rev_temp:\n",
    "    \n",
    "    if item[\"glasses\"] in glasses2:\n",
    "        item[\"glasses2\"] = item[\"glasses\"]\n",
    "        item[\"glasses\"] = \"None\"\n",
    "        item[\"glasses3\"] = \"None\"\n",
    "        item[\"glasses4\"] = \"None\"\n",
    "    elif item[\"glasses\"] in glasses3:\n",
    "        item[\"glasses3\"] = item[\"glasses\"]\n",
    "        item[\"glasses\"] = \"None\"\n",
    "        item[\"glasses2\"] = \"None\"\n",
    "        item[\"glasses4\"] = \"None\"\n",
    "    elif item[\"glasses\"] in glasses4:\n",
    "        item[\"glasses4\"] = item[\"glasses\"]\n",
    "        item[\"glasses\"] = \"None\"\n",
    "        item[\"glasses2\"] = \"None\"\n",
    "        item[\"glasses3\"] = \"None\"\n",
    "    else:\n",
    "        item[\"glasses2\"] = \"None\"\n",
    "        item[\"glasses3\"] = \"None\"\n",
    "        item[\"glasses4\"] = \"None\"\n",
    "        \n",
    "        \n",
    "    if item[\"mask\"] in beard1:\n",
    "        item[\"beard1\"] = item[\"mask\"]\n",
    "        item[\"mask\"] = \"None\"\n",
    "        item[\"beard2\"] = \"None\"\n",
    "    elif item[\"mask\"] in beard2:\n",
    "        item['beard2'] = item[\"mask\"]\n",
    "        item[\"beard1\"] = \"None\"\n",
    "        item[\"mask\"] = \"None\"\n",
    "    else:\n",
    "        item[\"beard1\"] = \"None\"\n",
    "        item[\"beard2\"] = \"None\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    if item[\"several\"] in several1:\n",
    "        item[\"several1\"] = item[\"several\"]\n",
    "        item[\"several\"] = \"None\"\n",
    "        item[\"several2\"] = \"None\"\n",
    "        item[\"several3\"] = \"None\"\n",
    "    elif item[\"several\"] in several2:\n",
    "        item[\"several2\"] = item[\"several\"]\n",
    "        item[\"several\"] = \"None\"\n",
    "        item[\"several1\"] = \"None\"\n",
    "        item[\"several3\"] = \"None\"\n",
    "    elif item[\"several\"] in several3:\n",
    "        item[\"several3\"] = item[\"several\"]\n",
    "        item[\"several\"] = \"None\"\n",
    "        item[\"several1\"] = \"None\"\n",
    "        item[\"several2\"] = \"None\"\n",
    "    else:\n",
    "        item[\"several1\"] = \"None\"\n",
    "        item[\"several2\"] = \"None\"\n",
    "        item[\"several3\"] = \"None\"\n",
    "        \n",
    "        \n",
    "    if item[\"hat\"] in hat2:\n",
    "        item[\"hat2\"] = item[\"hat\"]\n",
    "        item[\"hat\"] = \"None\"\n",
    "        item[\"hat3\"] = \"None\"\n",
    "        item[\"hat4\"] = \"None\"\n",
    "        item[\"hat5\"] = \"None\"\n",
    "    elif item[\"hat\"] in hat3:\n",
    "        item[\"hat3\"] = item[\"hat\"]\n",
    "        item[\"hat\"] = \"None\"\n",
    "        item[\"hat2\"] = \"None\"\n",
    "        item[\"hat4\"] = \"None\"\n",
    "        item[\"hat5\"] = \"None\"\n",
    "    elif item[\"hat\"] in hat4:\n",
    "        item[\"hat4\"] = item[\"hat\"]\n",
    "        item[\"hat\"] = \"None\"\n",
    "        item[\"hat2\"] = \"None\"\n",
    "        item[\"hat3\"] = \"None\"\n",
    "        item[\"hat5\"] = \"None\"\n",
    "    elif item[\"hat\"] in hat5:\n",
    "        item[\"hat5\"] = item[\"hat\"]\n",
    "        item[\"hat\"] = \"None\"\n",
    "        item[\"hat2\"] = \"None\"\n",
    "        item[\"hat3\"] = \"None\"\n",
    "        item[\"hat4\"] = \"None\"\n",
    "    else:\n",
    "        item[\"hat2\"] = \"None\"\n",
    "        item[\"hat3\"] = \"None\"\n",
    "        item[\"hat4\"] = \"None\"\n",
    "        item[\"hat5\"] = \"None\"\n",
    "        \n",
    "        \n",
    "    if item[\"clothing\"] in clothing2:\n",
    "        item[\"clothing2\"] = item[\"clothing\"]\n",
    "        item[\"clothing\"] = \"None\"\n",
    "    else:\n",
    "        item[\"clothing2\"] = \"None\"\n",
    "\n",
    "        \n",
    "\n",
    "    im1 = Image.open(f'./trait-layers/Background/{file_names_dict[item[\"background\"]]}.png').convert('RGBA')\n",
    "    im2 = Image.open(f'./trait-layers/Skins/{file_names_dict[item[\"skin\"]]}.png').convert('RGBA')\n",
    "    im3 = Image.open(f'./trait-layers/Several2/{file_names_dict[item[\"several2\"]]}.png').convert('RGBA')\n",
    "    im4 = Image.open(f'./trait-layers/Mask/{file_names_dict[item[\"mask\"]]}.png').convert('RGBA')\n",
    "    im5 = Image.open(f'./trait-layers/Clothing2/{file_names_dict[item[\"clothing2\"]]}.png').convert('RGBA') \n",
    "    im6 = Image.open(f'./trait-layers/Hat3/{file_names_dict[item[\"hat3\"]]}.png').convert('RGBA')   \n",
    "    im7 = Image.open(f'./trait-layers/Glasses2/{file_names_dict[item[\"glasses2\"]]}.png').convert('RGBA')                 \n",
    "    im8 = Image.open(f'./trait-layers/Hat/{file_names_dict[item[\"hat\"]]}.png').convert('RGBA') \n",
    "    im9 = Image.open(f'./trait-layers/Beard2/{file_names_dict[item[\"beard2\"]]}.png').convert('RGBA') \n",
    "    im10 = Image.open(f'./trait-layers/Glasses/{file_names_dict[item[\"glasses\"]]}.png').convert('RGBA') \n",
    "    im11 = Image.open(f'./trait-layers/Clothing/{file_names_dict[item[\"clothing\"]]}.png').convert('RGBA') \n",
    "    im12 = Image.open(f'./trait-layers/Glasses4/{file_names_dict[item[\"glasses4\"]]}.png').convert('RGBA') \n",
    "    im13 = Image.open(f'./trait-layers/Hat2/{file_names_dict[item[\"hat2\"]]}.png').convert('RGBA')   \n",
    "    im14 = Image.open(f'./trait-layers/Beard1/{file_names_dict[item[\"beard1\"]]}.png').convert('RGBA') \n",
    "    im15 = Image.open(f'./trait-layers/Hat5/{file_names_dict[item[\"hat5\"]]}.png').convert('RGBA') \n",
    "    im16 = Image.open(f'./trait-layers/Glasses3/{file_names_dict[item[\"glasses3\"]]}.png').convert('RGBA') \n",
    "    im17 = Image.open(f'./trait-layers/Several1/{file_names_dict[item[\"several1\"]]}.png').convert('RGBA')\n",
    "    im18 = Image.open(f'./trait-layers/Several3/{file_names_dict[item[\"several3\"]]}.png').convert('RGBA')\n",
    "    im19 = Image.open(f'./trait-layers/Hat4/{file_names_dict[item[\"hat4\"]]}.png').convert('RGBA')   \n",
    "    im20 = Image.open(f'./trait-layers/Hands/{file_names_dict[item[\"hand\"]]}.png').convert('RGBA')\n",
    "    im21 = Image.open(f'./trait-layers/Several/{file_names_dict[item[\"several\"]]}.png').convert('RGBA')\n",
    " \n",
    "    \n",
    "            \n",
    "    #Create each composite\n",
    "    com1 = Image.alpha_composite(im1, im2)\n",
    "    com2 = Image.alpha_composite(com1, im3)\n",
    "    com3 = Image.alpha_composite(com2, im4)\n",
    "    com4 = Image.alpha_composite(com3, im5)\n",
    "    com5 = Image.alpha_composite(com4, im6)\n",
    "    com6 = Image.alpha_composite(com5, im7)\n",
    "    com7 = Image.alpha_composite(com6, im8)\n",
    "    com8 = Image.alpha_composite(com7, im9)\n",
    "    com9 = Image.alpha_composite(com8, im10)\n",
    "    com10 = Image.alpha_composite(com9, im11)\n",
    "    com11 = Image.alpha_composite(com10, im12)\n",
    "    com12 = Image.alpha_composite(com11, im13)\n",
    "    com13 = Image.alpha_composite(com12, im14)\n",
    "    com14 = Image.alpha_composite(com13, im15)\n",
    "    com15 = Image.alpha_composite(com14, im16)\n",
    "    com16 = Image.alpha_composite(com15, im17)\n",
    "    com17 = Image.alpha_composite(com16, im18)\n",
    "    com18 = Image.alpha_composite(com17, im19)\n",
    "    com19 = Image.alpha_composite(com18, im20)\n",
    "    com20 = Image.alpha_composite(com19, im21)\n",
    "\n",
    "\n",
    "    #Convert to RGB\n",
    "    rgb_im = com20.convert('RGBA')\n",
    "    file_name = str(item[\"tokenId\"]) + \".png\"\n",
    "    rgb_im.save(\"../file/images/\" + file_name)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for tokens Traits \n",
    "METADATA_FILE_NAME = '../XXXX/metadata/all-traits.json'; \n",
    "with open(METADATA_FILE_NAME, 'w') as outfile:\n",
    "    json.dump(all_images_rev, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate Metadata for each Image    \n",
    "\n",
    "\n",
    "f = open('../XXXX/metadata/all-traits.json',) \n",
    "data = json.load(f)\n",
    "\n",
    "\n",
    "#########\n",
    "\n",
    "IMAGES_BASE_URI = \"XXXXXX\"\n",
    "PROJECT_NAME = \"FERRYMEN\"\n",
    "\n",
    "def getAttribute(key, value):\n",
    "    return {\n",
    "        \"trait_type\": key,\n",
    "        \"value\": value\n",
    "    }\n",
    "for i in data:\n",
    "    token_id = i['tokenId']\n",
    "    token = {\n",
    "        \"image\": IMAGES_BASE_URI + str(token_id) + '.png',\n",
    "        \"tokenId\": token_id,\n",
    "        \"name\": PROJECT_NAME + ' #' + str(token_id),\n",
    "        \"description\": \"Weaved by NYX, the Mother Night, Souls are the indivisible essence that defines us. They cross into the shadow lands when we sleep, meditate, daydream and when we die. Corrupted Wyverns and other creatures sweep these lands preying on travelers. There are those who dedicate their existence to guide and protect the crossing. They go by the name FERRYMEN.\",\n",
    "        \"attributes\": []\n",
    "    }\n",
    "    token[\"attributes\"].append(getAttribute(\"Ferrymen\", \"Oblivion\"))\n",
    "    token[\"attributes\"].append(getAttribute(\"Background\", i[\"background\"]))\n",
    "    token[\"attributes\"].append(getAttribute(\"Tribe\", i[\"skin\"]))\n",
    "    if getAttribute(\"Glasses\", i[\"glasses\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Glasses\", i[\"glasses\"]))\n",
    "    if getAttribute(\"Hat\", i[\"hat\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Hat\", i[\"hat\"]))\n",
    "    if getAttribute(\"Mask\", i[\"mask\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Facial Feature\", i[\"mask\"]))\n",
    "    if getAttribute(\"Several\", i[\"several\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Extra\", i[\"several\"]))\n",
    "    if getAttribute(\"Hand\", i[\"hand\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Hand\", i[\"hand\"]))\n",
    "    if getAttribute(\"Clothing\", i[\"clothing\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "        token[\"attributes\"].append(getAttribute(\"Clothes\", i[\"clothing\"]))\n",
    "    #if getAttribute(\"Ancestry\", i[\"ancestry\"])[\"value\"] !=  \"None\": #for traits with none\n",
    "    #    token[\"attributes\"].append(getAttribute(\"Ancestry\", i[\"ancestry\"]))\n",
    "  \n",
    "    with open('../XXXX/metadata/' + str(token_id) + '.json', 'w') as outfile:\n",
    "        json.dump(token, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Demigod', 'Royal']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.7]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ancestry_weights = [0.3, 0.7]\n",
    "ancestry_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other seals to the image:\n",
    "\n",
    "gods_file = pd.read_csv(\"Gods.csv\", header=0, usecols='ferrymenId')\n",
    "    \n",
    "def getAttribute(key, value):\n",
    "    return {\n",
    "        \"trait_type\": key,\n",
    "        \"value\": value\n",
    "    }\n",
    "        \n",
    "for i in range(0, 200):\n",
    "    if i not in gods_file.values:\n",
    "        ancestry_pick = random.choices(ancestry, ancestry_weights)[0]\n",
    "        im1 = Image.open(f'./images/{i}.png').convert('RGBA')\n",
    "        im2 = Image.open(f'./trait-layers/Ancestry/{file_names_dict[ancestry_pick]}.png').convert('RGBA')\n",
    "\n",
    "        #Create each composite\n",
    "        com1 = Image.alpha_composite(im1, im2)\n",
    "    \n",
    "    \n",
    "        #Convert to RGB\n",
    "        rgb_im = com1.convert('RGBA')\n",
    "        file_name = str(i) + \".png\"\n",
    "        rgb_im.save(\"../XXXX/images/\" + file_name)\n",
    "        \n",
    "        \n",
    "# Add trait in metadata\n",
    "        f = open(f'../XXXX/metadata/{i}.json',) \n",
    "        token = json.load(f)\n",
    "        token[\"attributes\"].append(getAttribute(\"Ancestry\", ancestry_pick))\n",
    "        \n",
    "        with open('../XXXX/metadata/' + str(i) + '.json', 'w') as outfile:\n",
    "            json.dump(token, outfile, indent=4)\n",
    "        #token = {\"attributes\": []}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add god seal to the image:\n",
    "\n",
    "\n",
    "for i in range(len(gods_file)):\n",
    "    god = gods_file.iloc[i].values[0]\n",
    "    im1 = Image.open(f'./images/{god}.png').convert('RGBA')\n",
    "    im2 = Image.open(f'./trait-layers/Ancestry/god.png').convert('RGBA')\n",
    "    \n",
    "    \n",
    "     #Create each composite\n",
    "    com1 = Image.alpha_composite(im1, im2)\n",
    "    \n",
    "    \n",
    "    #Convert to RGB\n",
    "    rgb_im = com1.convert('RGBA')\n",
    "    file_name = str(god) + \".png\"\n",
    "    rgb_im.save(\"../XXXX/images/\" + file_name)\n",
    "    \n",
    "    f = open(f'../XXXX/metadata/{i}.json',) \n",
    "    token = json.load(f)\n",
    "    token[\"attributes\"].append(getAttribute(\"Ancestry\", \"God\"))\n",
    "        \n",
    "    with open('../XXXX/metadata/' + str(i) + '.json', 'w') as outfile:\n",
    "        json.dump(token, outfile, indent=4)\n",
    "    #token = {\"attributes\": []}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
